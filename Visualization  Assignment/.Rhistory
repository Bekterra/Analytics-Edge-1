required(ggplot2, maps, ggmap)
requires(ggplot2, maps, ggmap)
require(ggplot2, maps, ggmap)
?required
??required
require(ggplot2, maps, ggmap)
require(ggplot2, maps, ggmaps)
install.packages("ggmaps")
install.packages("ggmap")
require(ggplot2, maps, ggmap)
require(ggplot2)
require(maps)
require(ggmap)
statesMap = map_data("state")
table(statesMap$groups)
table(statesMap$group)
dim(table(statesMap$group))
View(statesMap)
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black") + coord_map("mercator")
```
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "red") + coord_map("mercator")
polling=read.csv("PollingImputed.csv")
Train=subset(polling, Year %in% c(2004, 2008))
Test=subset(polling, Year == 2012)
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
TestPrediction = predict(mod2, newdata=Test, type="response")
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
table(TestPredictionBinary)
mean(TestPrediction)
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
predictionMap = predictionMap[order(predictionMap$order),]
dim(predictionMap)
dim(predictionMap)[1]
dim(statesMap)[1]
?merge
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary)) + geom_polygon(color = "black")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary)) + geom_polygon(color = "black")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary)) + geom_polygon(color = "black")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
TestPrediction
View(predictionDataFrame)
predictionDatFrame$TestPrediction[predictionDataFrame$Test.State == "Florida"]
predictionDataFrame$TestPrediction[predictionDataFrame$Test.State == "Florida"]
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black", linetype=3) + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black", fill=3) + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black", size=3) + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black", alpha=0.3) + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
parole=read.csv("parole.csv")
parole$male = as.factor(parole$male)
parole$state = as.factor(parole$state)
parole$crime = as.factor(parole$crime)
x=sum(parole$male)/length(parol$male)
x=sum(as.numeric(parole$male))/length(parol$male)
x=sum(as.numeric(parole$male))/length(parole$male)
table(parole$male)
as.numeric(parole$male)
sum(as.numeric(parole$male)-1)/length(parole$male)
130/(130+545)
as.numeric(parole$male)-1
2-as.numeric(parole$male)
sum(2-as.numeric(parole$male))/length(parole$male)
x=parole[parole$violator == 1]
parole[ parole$violator == 1]
parole$violator
parole$violator == 1
parole[parole$violator == 1]
parole[parole$violator == 1,]
x=parole[ parole$violator == 1,]
sum(2-as.numeric(x$male))/length(x$male)
table(parole$crime[ parole$state == 2,])
table(parole$crime[ parole$state == 2])
x=table(parole$crime[ parole$state == 2])
x
levels(x)
names(x)
names(x) = c("other", "larceny", "drug", "driving")
x
ggplot(data = parole, aes(x = age)) + geom_histogram()
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth=5)
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth=5, color="blue")
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth = 5) + facet_grid(male ~ .)
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth = 5) + facet_grid(.~male)
ggplot(data = parole, aes(x = age, fill = male)) + geom_histogram(binwidth = 5)
ggplot(data = parole, aes(x = age, fill = male)) +
geom_histogram(binwidth = 5, position="identity", alpha=0.5)
ggplot(data = parole, aes(x = age, fill = -male)) +
geom_histogram(binwidth = 5, position="identity", alpha=0.5)
ggplot(data = parole, aes(x = age, fill = male)) +
geom_histogram(binwidth = 5, position="identity", alpha=0.5)
ggplot(data = parole, aes(x = age, fill = !male)) +
geom_histogram(binwidth = 5, position="identity", alpha=0.5)
ggplot(data = parole, aes(x = age)) + geom_histogram()
ggplot(data = parole, aes(x = time.served)) + geom_histogram()
ggplot(data = parole, aes(x = time.served)) + geom_histogram(binwidth=1)
ggplot(data = parole, aes(x = time.served)) + geom_histogram(binwidth=0.1)
?ggplot
ggplot(data = parole, aes(x = time.served)) + geom_histogram(binwidth=1) +facet_grid(facets=time.served~.)
ggplot(data = parole, aes(x = time.served)) + geom_histogram(binwidth=1) +facet_grid(facets=crime~.)
ggplot(data = parole, aes(x = time.served)) + geom_histogram(binwidth=1) +facet_grid(facets=.~crime)
xx=parole
levels(xx$crime) = c("other", "larceny", "drugs", "driving")
ggplot(data = xx, aes(x = time.served)) + geom_histogram(binwidth=1) +facet_grid(facets=.~crime)
ggplot(data = xx, aes(x = time.served)) + geom_histogram(binwidth=1) +facet_grid(facets=crime~.)
ggplot(data = parole, aes(x = age, fill = crime)) +
geom_histogram(binwidth = 1, position="identity", alpha=0.5)
xx=parole
levels(xx$crime) = c("other", "larceny", "drugs", "driving")
ggplot(data = xx, aes(x = time.served, fill = crime)) +
geom_histogram(binwidth = 1, position="identity", alpha=0.5)
ggplot(data = xx, aes(x = time.served, fill = crime)) +
geom_histogram(binwidth = 1, position="identity", alpha=0.5) + scale_x_continuous(break=1)
geom_histogram(binwidth = 1, position="identity", alpha=0.5) + scale_x_continuous(breaks=1:5)
ggplot(data = xx, aes(x = time.served, fill = crime)) +
geom_histogram(binwidth = 1, position="identity", alpha=0.5) + scale_x_continuous(breaks=1:5)
ggplot(data = xx, aes(x = time.served, fill = crime)) +
geom_histogram(binwidth = 1, position="identity", alpha=0.5) + scale_x_continuous(breaks=0:7)
edges = read.csv("edges.csv")
users= read.csv("users.csv")
edges = read.csv("edges.csv")
users= read.csv("users.csv")
View(edges)
View(order(edges))
?order
sort.list(edges)
base:::order(edges)
View(edges[base:::order(edges)])
View(edges[base:::order(edges),])
table(edges$V1)
table(edges$V2)
??union
table(edges$V1)+table(edges$V2)
?join
??join
cbind(table(edges$V1), table(edges$V2))
merge(table(edges$V1), table(edges$V2), all.x=TRUE, all.y=TRUE)
names(table(edges$V1))
146*2/59
length(edges)
length(edges$V1)
table(users$school, users$locale)
table(users$school, users$gender)
install.packages("igraph")
require(igraph)
?graph.data.frame
graph.data.frame(edges, TRUE, users)
print(g, e=TRUE, v=TRUE)
g = graph.data.frame(edges, TRUE, users)
print(g, e=TRUE, v=TRUE)
demo(package="igraph")
?demo
demo(centrality, package="igraph")
demo(centrality, package="igraph")
g = graph.data.frame(edges, TRUE, users)
g = graph.data.frame(edges, FALSE, users)
print(g, e=TRUE, v=TRUE)
plot(g, vertex.size=5, vertex.label=NA)
x = degree(g)
sum(x >= 10)
table(x >= 10)
V(g)$size = degree(g)/2+2
plot(g, vertex.label=NA)
max(V(g)$size)
class(g)
?plot.igraph
min(V(g)$size)
V(g)$color = "black"
V(g)$color[V(g)$gender == "A"] = "red"
V(g)$color[V(g)$gender == "B"] = "gray"
plot(g, vertex.label=NA)
layout.random(g)
plot(g, vertex.label=NA)
layout.circle(g);
plot(g, vertex.label=NA)
layout.sphere(g);
plot(g, vertex.label=NA)
layout.fruchterman(g);
layout.fruchterman.reingold(g);
plot(g, vertex.label=NA)
layout.kamada.kawai(g);
plot(g, vertex.label=NA)
layout.spring(g);
plot(g, vertex.label=NA)
layout.reingold.tilford(g);
plot(g, vertex.label=NA)
layout.fruchterman.reingold.grid(g);
plot(g, vertex.label=NA)
layout.lgl(g);
plot(g, vertex.label=NA)
layout.graphopt(g);
plot(g, vertex.label=NA)
layout.svd(g);
plot(g, vertex.label=NA)
layout.norm(g);
layout.auto(g)
plot(g, vertex.label=NA)
plot(g, vertex.label=NA)
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "green"
plot(g, vertex.label=NA)
V(g)$color = "black"
V(g)$color[V(g)$locale == "A"] = "red"
V(g)$color[V(g)$locale == "B"] = "green"
plot(g, vertex.label=NA)
?igraph.plotting
?plot.igraph
tweets=read.csv("tweets.csv", stringsAsFactors=FALSE)
require(tm)
install.packages("tm")
install.packages("SnowballC")
require(tm)
require(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
frequencies
findFreqTerms(frequencies, lowfreq=20)
inspect(frequencies[1000:1005,505:515])
sparse=frequencies
tweetsframe = as.data.frame(as.matrix(sparse))
`r dim(tweetsframe)[2]`
dim(tweetsframe)[2]
# VISUALIZING TEXT DATA USING WORD CLOUDS
```{r}
require(tm)
require(SnowballC)
tweets=read.csv("tweets.csv", stringsAsFactors=FALSE)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
# Check for sparsity
#findFreqTerms(frequencies, lowfreq=20)
# Remove sparse terms
#sparse = removeSparseTerms(frequencies, 0.995)
sparse=frequencies
tweetsframe = as.data.frame(as.matrix(sparse))
install.packages("wordcloud")
require(wordcloud)
allTweets = as.data.frame(as.matrix(sparse))
str(allTweets)
rownames(allTweets)
colnames(allTweets)
colSums(allTweets)
?wordcloud
wordcloud(colnames(allTweets), colSums(allTweets))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE, random.color=TRUE, fixed.asp=FALSE)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE, random.color=TRUE, fixed.asp=FALSE, rot.per=0)
?color
?colors
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE, random.color=TRUE, fixed.asp=FALSE, rot.per=0, color=Pastel1)
library(RColorBrewer)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE, random.color=TRUE, fixed.asp=FALSE, rot.per=0, color=Pastel1)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE, random.color=TRUE, fixed.asp=FALSE, rot.per=0, color=Dark2)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE, random.color=TRUE, fixed.asp=FALSE, rot.per=0, colors=Pastel1)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), ordered.colors=TRUE, random.color=TRUE, fixed.asp=FALSE, rot.per=0, colors="Pastel1")
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
require(tm)
require(SnowballC)
tweets=read.csv("tweets.csv", stringsAsFactors=FALSE)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
dim(allTweets)[2]
require(wordcloud)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
table(Tweet$avg)
table(tweets$avg)
table(tweets$Avg)
tweets$Tweet[ tweets$Avg == -1]
tweets$Tweet[ tweets$Avg <= -1]
corpus = Corpus(VectorSource(tweets$Tweet[ tweets$Avg <= -1 ]))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
wordcloud(colnames(allTweets), colSums(allTweets))
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 3)
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 4)
pal2 = brewer.pal(8,"Dark2")
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 4, colors=pal2)
display.brewer.all(8)
pal2 = brewer.pal(8,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 4, colors=pal2)
pal2 = brewer.pal(4,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 4, colors=pal2)
pal2 = brewer.pal(32,"BuPu")
pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 4, colors=pal2)
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 3, colors=pal2)
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 2, colors=pal2)
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 1, colors=pal2)
?wordcloud
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 2, max.words=100, ordered.colors=TRUE)
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 2, max.words=100, ordered.colors=TRUE, colors="blue")
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 2, max.words=100, ordered.colors=TRUE, colors=c("blue", "red")
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 2, max.words=100, ordered.colors=TRUE, colors=c("blue", "red"))
wordcloud(colnames(allTweets), colSums(allTweets), min.freq = 2, max.words=100, colors=c("blue", "red"))
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE)
corpus = Corpus(VectorSource(tweets$Tweet))  #[ tweets$Avg <= -1 ]
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), random.order=F)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), rot.per=0.3)
display.brewer.all()
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "Blues"))
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "Blues")[-1,-2,-3,-4])
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "Blues")[c(-1,-2,-3,-4)])
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "Blues")[c(-1,-2,-3,-4)], min.freq=2, ordered.colors=T)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "Blues")[c(-1,-2,-3,-4)], ordered.colors=T)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "Blues")[c(-1,-2,-3,-4)], min.freq=2, random.order=F)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "BuPu")[c(-1,-2,-3,-4)], min.freq=2, random.order=F)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25), colors=brewer.pal(9, "BuPu")[c(-1,-2,-3,-4)], min.freq=3, random.order=F)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "BuPu")[c(-1,-2,-3,-4)], min.freq=3, random.order=F)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "BuPu")[c(-1,-2,-3)], min.freq=10, random.order=F)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "BuPu")[c(-1,-2,-3)], min.freq=5, random.order=F)
#pal2 = brewer.pal(9,"BuPu")
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "BuPu")[c(-1,-2,-3)], min.freq=6, random.order=F)
